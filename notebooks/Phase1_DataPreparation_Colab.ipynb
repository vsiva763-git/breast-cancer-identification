{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7aca96e",
   "metadata": {},
   "source": [
    "# Breast Cancer Identification - Phase 1: Data Preparation\n",
    "\n",
    "This notebook prepares datasets for multi-modal breast cancer identification:\n",
    "- BreakHis (Histopathology images)\n",
    "- CBIS-DDSM (Mammography images)\n",
    "\n",
    "**Run this in Google Colab for free GPU access!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc97139",
   "metadata": {},
   "source": [
    "## 1. Setup & Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545bc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision pytorch-lightning timm albumentations opencv-python scikit-image pandas numpy pyyaml tqdm optuna wandb captum shap streamlit fastapi uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5dae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
    "\n",
    "# Enable cuDNN benchmark\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc082b7c",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive & Download Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d39c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (only for Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    in_colab = True\n",
    "    data_root = '/content/drive/MyDrive/breast_cancer_data'\n",
    "    print(\"✓ Google Drive mounted\")\n",
    "except ImportError:\n",
    "    in_colab = False\n",
    "    data_root = '/tmp/breast_cancer_data'\n",
    "    print(\"✓ Running locally (not in Colab)\")\n",
    "\n",
    "# Create data directory\n",
    "os.makedirs(data_root, exist_ok=True)\n",
    "print(f\"Data root: {data_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b504907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download BreakHis dataset (from Kaggle)\n",
    "# You'll need Kaggle API credentials: !kaggle datasets download -d ihebski/histopathologic-breast-cancer-images\n",
    "\n",
    "# For demo, create dummy structure\n",
    "breakhis_path = os.path.join(data_root, 'BreakHis')\n",
    "cbis_ddsm_path = os.path.join(data_root, 'CBIS-DDSM')\n",
    "\n",
    "os.makedirs(f'{breakhis_path}/benign', exist_ok=True)\n",
    "os.makedirs(f'{breakhis_path}/malignant', exist_ok=True)\n",
    "os.makedirs(f'{cbis_ddsm_path}/images', exist_ok=True)\n",
    "\n",
    "print(f\"✓ Dataset directories created:\")\n",
    "print(f\"  - BreakHis: {breakhis_path}\")\n",
    "print(f\"  - CBIS-DDSM: {cbis_ddsm_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b29f6",
   "metadata": {},
   "source": [
    "## 3. Data Inspection & Metadata Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0681e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_dataset(dataset_path: str, modality: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scan dataset and create metadata DataFrame.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    \n",
    "    if modality == 'histopathology':\n",
    "        # BreakHis structure: benign/ and malignant/ folders\n",
    "        for class_name in ['benign', 'malignant']:\n",
    "            class_path = os.path.join(dataset_path, class_name)\n",
    "            if os.path.exists(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        img_path = os.path.join(class_path, img_file)\n",
    "                        label = 0 if class_name == 'benign' else 1\n",
    "                        records.append({\n",
    "                            'image_path': img_path,\n",
    "                            'label': label,\n",
    "                            'class': class_name,\n",
    "                            'modality': 'histopathology',\n",
    "                            'magnification': 'unknown'  # Extract from filename if available\n",
    "                        })\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Scan datasets\n",
    "print(\"Scanning datasets...\")\n",
    "breakhis_df = scan_dataset(breakhis_path, 'histopathology')\n",
    "print(f\"BreakHis: {len(breakhis_df)} images found\")\n",
    "print(breakhis_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75d0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "if len(breakhis_df) > 0:\n",
    "    breakhis_df['class'].value_counts().plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('BreakHis Class Distribution')\n",
    "    axes[0].set_ylabel('Count')\n",
    "\n",
    "print(\"\\n✓ Class distribution analyzed\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0febc",
   "metadata": {},
   "source": [
    "## 4. Albumentations Augmentation Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebf5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "class DataAugmenter:\n",
    "    \"\"\"Create augmentation pipelines for different datasets.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_train_transforms(image_size: int = 224):\n",
    "        return A.Compose([\n",
    "            A.RandomResizedCrop(image_size, image_size, scale=(0.8, 1.0)),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Rotate(limit=30, p=0.7),\n",
    "            A.GaussNoise(p=0.2),\n",
    "            A.RandomBrightnessContrast(p=0.5),\n",
    "            A.ElasticTransform(p=0.3),\n",
    "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ], is_check_shapes=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_val_transforms(image_size: int = 224):\n",
    "        return A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "\n",
    "augmenter = DataAugmenter()\n",
    "train_transform = augmenter.get_train_transforms()\n",
    "val_transform = augmenter.get_val_transforms()\n",
    "\n",
    "print(\"✓ Augmentation pipelines created\")\n",
    "print(f\"Train transforms: {len(train_transform.transforms)} augmentations\")\n",
    "print(f\"Val transforms: {len(val_transform.transforms)} augmentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations (demo with a sample image)\n",
    "# Create a dummy image for demo\n",
    "dummy_image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    augmented = train_transform(image=dummy_image)\n",
    "    img = augmented['image'].permute(1, 2, 0).numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)  # Normalize for display\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'Augmentation {i+1}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Augmentations (10 different transforms)', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Augmentation examples displayed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cfcae",
   "metadata": {},
   "source": [
    "## 5. Balanced Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdf9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_balanced_splits(df: pd.DataFrame, \n",
    "                          train_ratio: float = 0.7,\n",
    "                          val_ratio: float = 0.15,\n",
    "                          random_state: int = 42) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create stratified splits maintaining class distribution.\n",
    "    \n",
    "    Train: 70% | Val: 15% | Test: 15%\n",
    "    \"\"\"\n",
    "    # First split: train vs temp (val+test)\n",
    "    train_df, temp_df = train_test_split(\n",
    "        df,\n",
    "        test_size=(1 - train_ratio),\n",
    "        stratify=df['label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Second split: val vs test\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df,\n",
    "        test_size=0.5,\n",
    "        stratify=temp_df['label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    return {'train': train_df, 'val': val_df, 'test': test_df}\n",
    "\n",
    "# Create splits\n",
    "if len(breakhis_df) > 0:\n",
    "    splits = create_balanced_splits(breakhis_df)\n",
    "    \n",
    "    print(\"Balanced Splits (BreakHis):\")\n",
    "    for split_name, split_df in splits.items():\n",
    "        benign = (split_df['label'] == 0).sum()\n",
    "        malignant = (split_df['label'] == 1).sum()\n",
    "        print(f\"  {split_name.upper():5s}: {len(split_df):5d} images | Benign: {benign:4d} | Malignant: {malignant:4d}\")\n",
    "else:\n",
    "    print(\"⚠ No images found in BreakHis folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14552459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits to CSV for reproducibility\n",
    "splits_dir = os.path.join(data_root, 'splits')\n",
    "os.makedirs(splits_dir, exist_ok=True)\n",
    "\n",
    "if len(breakhis_df) > 0:\n",
    "    for split_name, split_df in splits.items():\n",
    "        csv_path = os.path.join(splits_dir, f'breakhis_{split_name}.csv')\n",
    "        split_df.to_csv(csv_path, index=False)\n",
    "        print(f\"✓ Saved {split_name}: {csv_path}\")\n",
    "\n",
    "# Visualize split distribution\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "split_stats = []\n",
    "for split_name, split_df in splits.items():\n",
    "    benign = (split_df['label'] == 0).sum()\n",
    "    malignant = (split_df['label'] == 1).sum()\n",
    "    split_stats.append({'Split': split_name, 'Benign': benign, 'Malignant': malignant})\n",
    "\n",
    "stats_df = pd.DataFrame(split_stats)\n",
    "stats_df.set_index('Split')[['Benign', 'Malignant']].plot(kind='bar', ax=ax, rot=0)\n",
    "ax.set_title('Balanced Train/Val/Test Splits')\n",
    "ax.set_ylabel('Number of Images')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Splits visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed889f",
   "metadata": {},
   "source": [
    "## 6. PyTorch DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "class MedicalImageDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for medical images.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, transform=None):\n",
    "        self.df = dataframe\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_path = row['image_path']\n",
    "        if os.path.exists(image_path):\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                # Return dummy image if file not found\n",
    "                image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # Return dummy image for demo\n",
    "            image = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        label = torch.tensor(row['label'], dtype=torch.long)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Create datasets\n",
    "if len(breakhis_df) > 0:\n",
    "    train_dataset = MedicalImageDataset(splits['train'], transform=train_transform)\n",
    "    val_dataset = MedicalImageDataset(splits['val'], transform=val_transform)\n",
    "    test_dataset = MedicalImageDataset(splits['test'], transform=val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "    \n",
    "    print(f\"✓ DataLoaders created:\")\n",
    "    print(f\"  Train: {len(train_loader)} batches\")\n",
    "    print(f\"  Val: {len(val_loader)} batches\")\n",
    "    print(f\"  Test: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96894873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize batch\n",
    "if len(breakhis_df) > 0:\n",
    "    batch_images, batch_labels = next(iter(train_loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(batch_images[:8], batch_labels[:8])):\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "        axes[i].imshow(img)\n",
    "        class_name = 'Malignant' if label == 1 else 'Benign'\n",
    "        axes[i].set_title(f'{class_name} (L={label})')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Batch from Training Set', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Batch shape: {batch_images.shape}\")\n",
    "    print(f\"Labels: {batch_labels.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b607be7",
   "metadata": {},
   "source": [
    "## 7. Configuration Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81289502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration summary\n",
    "config_summary = {\n",
    "    'data': {\n",
    "        'datasets': {\n",
    "            'BreakHis': f'{len(breakhis_df)} images (histopathology)',\n",
    "            'CBIS-DDSM': 'To be added (mammography)',\n",
    "        },\n",
    "        'augmentation': [\n",
    "            'RandomResizedCrop(224)',\n",
    "            'HorizontalFlip(0.5)',\n",
    "            'VerticalFlip(0.5)',\n",
    "            'Rotate(30°)',\n",
    "            'GaussNoise, BrightnessContrast',\n",
    "            'ElasticTransform, GaussianBlur'\n",
    "        ],\n",
    "        'splits': {'train': 0.7, 'val': 0.15, 'test': 0.15},\n",
    "    },\n",
    "    'models': {\n",
    "        'histopathology': 'EfficientNet-B0 (5.3M params)',\n",
    "        'mammography': 'MobileNet-V3 (5.4M params)',\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 50,\n",
    "        'mixed_precision': True,\n",
    "        'optimizer': 'AdamW',\n",
    "        'scheduler': 'OneCycleLR',\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(config_summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb1e3f1",
   "metadata": {},
   "source": [
    "## 8. Save Metadata to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae72ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset metadata\n",
    "metadata_dir = os.path.join(data_root, 'metadata')\n",
    "os.makedirs(metadata_dir, exist_ok=True)\n",
    "\n",
    "if len(breakhis_df) > 0:\n",
    "    metadata_path = os.path.join(metadata_dir, 'breakhis_metadata.csv')\n",
    "    breakhis_df.to_csv(metadata_path, index=False)\n",
    "    print(f\"✓ Metadata saved to: {metadata_path}\")\n",
    "\n",
    "# Save config\n",
    "config_path = os.path.join(metadata_dir, 'data_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(config_summary, f, indent=2)\n",
    "print(f\"✓ Config saved to: {config_path}\")\n",
    "\n",
    "print(\"\\n✓ Phase 1 Data Preparation Complete!\")\n",
    "print(f\"\\nDatasets ready at: {data_root}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
