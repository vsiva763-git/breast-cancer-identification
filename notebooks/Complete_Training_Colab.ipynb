{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869dc093",
   "metadata": {},
   "source": [
    "# üéØ Breast Cancer Identification - Complete Training Pipeline\n",
    "## End-Semester Project | IEEE 2024 Based Approach\n",
    "\n",
    "**Dataset**: BreakHis (7,909 histopathology images)\n",
    "**Model**: EfficientNet-B0 with Transfer Learning\n",
    "**Expected Accuracy**: 95-97%\n",
    "**Training Time**: 2-3 hours on T4 GPU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b899e2ff",
   "metadata": {},
   "source": [
    "## üìã Step 1: Check GPU and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úì PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27715a1",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b24509",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required packages (suppress output)\n",
    "!pip install timm==0.9.8\n",
    "!pip install albumentations==1.4.3\n",
    "!pip install pytorch-lightning==2.1.3\n",
    "!pip install wandb==0.16.3\n",
    "!pip install scikit-learn==1.3.2\n",
    "!pip install opencv-python==4.8.1\n",
    "!pip install pyyaml==6.0.1\n",
    "\n",
    "print(\"‚úì All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3b615",
   "metadata": {},
   "source": [
    "## üíæ Step 3: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de56895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Drive\n",
    "project_dir = '/content/drive/MyDrive/breast_cancer_project'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.chdir(project_dir)\n",
    "\n",
    "print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83febd25",
   "metadata": {},
   "source": [
    "## üì• Step 4: Clone Repository and Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository\n",
    "!git clone https://github.com/vsiva763-git/breast-cancer-identification.git\n",
    "%cd breast-cancer-identification\n",
    "\n",
    "# Create data directory\n",
    "!mkdir -p data\n",
    "\n",
    "print(\"‚úì Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e120cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download BreakHis dataset (~1.2 GB, takes 10-20 minutes)\n",
    "!python download_breakhis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6347ac6f",
   "metadata": {},
   "source": [
    "## üîç Step 5: Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674a754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Check dataset structure\n",
    "breakhis_path = Path('data/BreaKHis_v1')\n",
    "\n",
    "if breakhis_path.exists():\n",
    "    print(\"‚úì BreakHis dataset found!\\n\")\n",
    "    \n",
    "    # Count images\n",
    "    benign_images = list(breakhis_path.rglob('*benign*.png'))\n",
    "    malignant_images = list(breakhis_path.rglob('*malignant*.png'))\n",
    "    \n",
    "    print(f\"üìä Dataset Statistics:\")\n",
    "    print(f\"   Benign: {len(benign_images)} images\")\n",
    "    print(f\"   Malignant: {len(malignant_images)} images\")\n",
    "    print(f\"   Total: {len(benign_images) + len(malignant_images)} images\")\n",
    "    \n",
    "    # Display sample images\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Sample BreakHis Images', fontsize=16)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < 4:\n",
    "            img_path = random.choice(benign_images)\n",
    "            label = \"Benign\"\n",
    "        else:\n",
    "            img_path = random.choice(malignant_images)\n",
    "            label = \"Malignant\"\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{label}\\n{img_path.name[:20]}...\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found. Please run download cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffece2d",
   "metadata": {},
   "source": [
    "## üîß Step 6: Phase 1 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857122d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data preparation\n",
    "!python phase1_data_preparation/prepare_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fcfcb4",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Step 7: Phase 2 - Model Training\n",
    "\n",
    "### Option A: Quick Training (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a quick test configuration (5 epochs)\n",
    "import yaml\n",
    "\n",
    "# Load config and modify for quick test\n",
    "with open('configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['models']['training']['epochs'] = 5\n",
    "config['models']['training']['batch_size'] = 32\n",
    "\n",
    "# Save test config\n",
    "with open('configs/config_test.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úì Quick test configuration created (5 epochs)\")\n",
    "print(\"   This will take ~15-20 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40692135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quick training test\n",
    "!python phase2_model_development/train.py --config configs/config_test.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c6544",
   "metadata": {},
   "source": [
    "### Option B: Full Training (50 epochs, ~2-3 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Weights & Biases for experiment tracking (optional)\n",
    "import wandb\n",
    "\n",
    "# Login to W&B (get API key from https://wandb.ai/authorize)\n",
    "wandb.login()\n",
    "\n",
    "print(\"‚úì W&B configured for experiment tracking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full training with all 50 epochs\n",
    "!python phase2_model_development/train.py --config configs/config.yaml --wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2776c6b",
   "metadata": {},
   "source": [
    "## üìä Step 8: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd008a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load best model checkpoint\n",
    "checkpoint_path = 'checkpoints/best_model.pth'\n",
    "\n",
    "if Path(checkpoint_path).exists():\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    print(\"üìà Training Results:\")\n",
    "    print(f\"   Best Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"   Best Val Accuracy: {checkpoint.get('val_accuracy', 'N/A'):.2%}\")\n",
    "    print(f\"   Best Val Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "    \n",
    "    # If predictions are saved\n",
    "    if 'test_predictions' in checkpoint:\n",
    "        y_true = checkpoint['test_labels']\n",
    "        y_pred = checkpoint['test_predictions']\n",
    "        \n",
    "        # Classification Report\n",
    "        print(\"\\nüìä Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=['Benign', 'Malignant']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Benign', 'Malignant'],\n",
    "                    yticklabels=['Benign', 'Malignant'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found. Train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179cd3c",
   "metadata": {},
   "source": [
    "## üíæ Step 9: Save Results to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3817731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped results folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = f\"/content/drive/MyDrive/breast_cancer_results_{timestamp}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Copy important files\n",
    "files_to_save = [\n",
    "    'checkpoints/best_model.pth',\n",
    "    'configs/config.yaml',\n",
    "    'logs/training.log'\n",
    "]\n",
    "\n",
    "for file_path in files_to_save:\n",
    "    if Path(file_path).exists():\n",
    "        shutil.copy(file_path, results_dir)\n",
    "        print(f\"‚úì Saved: {file_path}\")\n",
    "\n",
    "print(f\"\\n‚úì All results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777e0e7",
   "metadata": {},
   "source": [
    "## üé® Step 10: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0db303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Load training history if available\n",
    "history_path = 'logs/training_history.json'\n",
    "\n",
    "if Path(history_path).exists():\n",
    "    with open(history_path, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # Plot training curves\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val Accuracy', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{results_dir}/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úì Training curves saved to {results_dir}/training_curves.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Training history not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98981f7c",
   "metadata": {},
   "source": [
    "## üéØ Step 11: Make Predictions on New Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import timm\n",
    "\n",
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = timm.create_model('efficientnet_b0', pretrained=False, num_classes=2)\n",
    "\n",
    "# Load weights\n",
    "checkpoint = torch.load('checkpoints/best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Predict single image.\"\"\"\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        pred_class = torch.argmax(probabilities, dim=1).item()\n",
    "        confidence = probabilities[0][pred_class].item()\n",
    "    \n",
    "    label = \"Malignant\" if pred_class == 1 else \"Benign\"\n",
    "    return label, confidence\n",
    "\n",
    "# Test on sample images\n",
    "test_images = random.sample(benign_images + malignant_images, 4)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for ax, img_path in zip(axes, test_images):\n",
    "    prediction, confidence = predict_image(img_path)\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"Pred: {prediction}\\nConf: {confidence:.2%}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Model ready for predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18497ea9",
   "metadata": {},
   "source": [
    "## üìù Summary and Next Steps\n",
    "\n",
    "### ‚úÖ Completed:\n",
    "1. ‚úì Dataset downloaded (BreakHis - 7,909 images)\n",
    "2. ‚úì Data preparation with augmentation\n",
    "3. ‚úì Model training with EfficientNet-B0\n",
    "4. ‚úì Model evaluation and metrics\n",
    "5. ‚úì Results saved to Google Drive\n",
    "\n",
    "### üéØ Next Steps:\n",
    "1. **Phase 3**: Multi-modal fusion (if using multiple datasets)\n",
    "2. **Phase 4**: Explainability (Grad-CAM, SHAP)\n",
    "3. **Phase 5**: Deployment (Streamlit app)\n",
    "\n",
    "### üìä Expected Results:\n",
    "- **Accuracy**: 95-97%\n",
    "- **Training Time**: 2-3 hours on T4 GPU\n",
    "- **Model Size**: ~20 MB\n",
    "\n",
    "### üìö References:\n",
    "- BreakHis Dataset: https://web.inf.ufpr.br/vri/databases/\n",
    "- EfficientNet Paper: https://arxiv.org/abs/1905.11946\n",
    "- Repository: https://github.com/vsiva763-git/breast-cancer-identification"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
