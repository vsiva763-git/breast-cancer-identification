# Breast Cancer Identification - Multi-Modal Deep Learning System

## ğŸ¯ Project Overview

This is an **end-semester project** implementing a comprehensive **Multi-Modal Breast Cancer Identification System** using deep learning. The system analyzes both histopathology and mammography images to classify cancerous tissue with state-of-the-art accuracy.

### Key Features
- âœ… **Multi-Modal Learning**: Combines histopathology (microscopic tissue) and mammography (X-ray) imaging
- âœ… **Lightweight Models**: EfficientNet-B0 and MobileNet-V3 for efficient inference (~15M parameters)
- âœ… **Explainability**: Grad-CAM heatmaps, SHAP values, attention visualizations
- âœ… **Mixed Precision Training**: 40% faster training with 50% less memory usage
- âœ… **Production Ready**: Streamlit dashboard + FastAPI backend
- âœ… **100% Free Stack**: All tools, hosting, and GPU training are completely free

---

## ğŸ—ï¸ 5-Phase Development Architecture

### Phase 1: Data Preparation âœ…
- Loads BreakHis (histopathology) and CBIS-DDSM (mammography) datasets
- Advanced augmentation with Albumentations
- Balanced train/val/test splits (70/15/15)
- Google Drive integration for Colab workflow

**Files**: [prepare_data.py](phase1_data_preparation/prepare_data.py) | [data_utils.py](utils/data_utils.py)

### Phase 2: Lightweight Model Development âœ…
- **Histopathology**: EfficientNet-B0 (5.3M params)
- **Mammography**: MobileNet-V3 (5.4M params)
- Mixed precision training (FP16)
- Early stopping + knowledge distillation

**Files**: [train.py](phase2_model_development/train.py) | [model_utils.py](utils/model_utils.py)

### Phase 3: Multi-Modal Fusion âœ…
Three fusion strategies:
1. **Early Fusion**: Concatenate features before classification
2. **Late Fusion**: Average classification outputs  
3. **Attention-Based Fusion** (Primary): Learn optimal modality weighting

```
Mammography (EfficientNet) â”€â”
                            â”œâ”€â†’ Attention Fusion â†’ Classification
Histopathology (MobileNet) â”€â”˜
```

**Files**: [fusion.py](phase3_multimodal_fusion/fusion.py)

### Phase 4: Explainability (XAI) âœ…
- **Grad-CAM**: Attention maps showing decision regions
- **Saliency Maps**: Gradient-based pixel importance
- **SHAP Values**: Feature-level importance scores
- **Attention Weights**: Modality contribution visualization

**Files**: [xai.py](phase4_explainability/xai.py)

### Phase 5: Deployment âœ…
- **Streamlit Dashboard**: Interactive UI (free hosting on Streamlit Cloud)
- **FastAPI Backend**: REST API for inference
- **Docker**: Container for reproducible deployment

**Files**: [streamlit_app.py](phase5_deployment/streamlit_app.py) | [api.py](phase5_deployment/api.py)

---

## ğŸ“Š Tech Stack (All Free!)

| Component | Tool | Why |
|-----------|------|-----|
| **GPU Training** | Google Colab | Free 12GB GPU/TPU access |
| **Storage** | Google Drive | 15GB free, seamless Colab |
| **Deep Learning** | PyTorch | Simpler, more efficient |
| **Models** | Timm | 1000+ pre-trained models |
| **Augmentation** | Albumentations | Fast, GPU-accelerated |
| **XAI** | Captum + SHAP | Free interpretability |
| **Dashboard** | Streamlit | Free cloud hosting |
| **API** | FastAPI | Modern, async, fast |
| **Datasets** | BreakHis, CBIS-DDSM | Public, free |
| **Version Control** | GitHub | Free repos + CI/CD |

---

## âš¡ Quick Start

### 1. Clone & Install
```bash
git clone https://github.com/vsiva763-git/breast-cancer-identification.git
cd breast-cancer-identification
pip install -r requirements.txt
```

### 2. Download Datasets
- **BreakHis**: https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database/
- **CBIS-DDSM**: https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-dataset
- Store in `data/BreakHis/` and `data/CBIS-DDSM/`

### 3. Prepare Data
```bash
python phase1_data_preparation/prepare_data.py
```

### 4. Train Models (Google Colab)
```bash
python phase2_model_development/train.py
```

### 5. Deploy
```bash
# Streamlit
streamlit run phase5_deployment/streamlit_app.py

# FastAPI
python phase5_deployment/api.py

# Docker
docker build -t cancer-id .
docker run -p 8000:8000 -p 8501:8501 cancer-id
```

---

## ğŸ“ˆ Expected Performance

- **Accuracy**: 95-97%
- **Sensitivity**: 94-96%
- **Specificity**: 95-97%
- **Inference Time**: 200-500ms per image
- **Model Size**: 15-20MB (quantized)
- **Training Time**: 2-3 hours on Colab T4 GPU

---

## ğŸ“ Project Structure

```
breast-cancer-identification/
â”œâ”€â”€ phase1_data_preparation/      # Data loading & augmentation
â”œâ”€â”€ phase2_model_development/     # Model training pipelines
â”œâ”€â”€ phase3_multimodal_fusion/     # Fusion architecture
â”œâ”€â”€ phase4_explainability/        # XAI methods (Grad-CAM, SHAP)
â”œâ”€â”€ phase5_deployment/            # Streamlit app & FastAPI
â”œâ”€â”€ utils/                        # Helper functions
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â””â”€â”€ model_utils.py
â”œâ”€â”€ configs/                      # YAML configurations
â”œâ”€â”€ notebooks/                    # Jupyter notebooks
â”œâ”€â”€ requirements.txt              # All dependencies
â”œâ”€â”€ Dockerfile                    # Container config
â””â”€â”€ README.md
```

---

## ğŸ”— Deployment Architectures

### Local Development
```
GitHub â†’ Clone â†’ Colab/Local â†’ Train Models â†’ Save Checkpoints â†’ Google Drive
```

### Production (Free)
```
GitHub â†’ Streamlit Cloud (free) â† Model from Google Drive
         â†“
       FastAPI (Google Cloud Run free tier)
```

---

## ğŸ“š Datasets

| Dataset | Images | Modality | Classes | Source |
|---------|--------|----------|---------|--------|
| **BreakHis** | 7,909 | Histopathology | 8 | UFPR, Brazil |
| **CBIS-DDSM** | ~6,000 | Mammography | 3 | Kaggle (NIH) |
| **INbreast** | 1,640 | Mammography | 3 | U. Lisbon |

---

## ğŸš€ Advanced Features

âœ¨ Implemented within free constraints:
- [x] Multi-modal fusion
- [x] Attention mechanisms
- [x] Data augmentation
- [x] Mixed precision training
- [x] Model optimization
- [x] XAI visualizations
- [x] Web interface
- [x] Experiment tracking (Weights & Biases free)
- [x] Docker containerization
- [x] Hyperparameter tuning (Optuna)

---

## ğŸ“– IEEE Paper Reference

This project is based on state-of-the-art research in breast cancer detection. Key references:

1. **EfficientNet**: https://arxiv.org/abs/1905.11946
2. **MobileNetV3**: https://arxiv.org/abs/1905.02175
3. **Grad-CAM**: https://arxiv.org/abs/1610.02055
4. **Multi-Modal Learning**: Multiple fusion strategies for medical imaging
5. **BreakHis Dataset**: https://arxiv.org/abs/1506.01497

For recent papers, check:
- arXiv: https://arxiv.org/search/?query=breast+cancer+detection
- IEEE: https://ieeexplore.ieee.org/Xplore/home.jsp

---

## ğŸ“ For Your End-Semester Project

This project covers all important aspects:
- âœ… Data preprocessing & augmentation
- âœ… Deep learning model training
- âœ… Multi-modal fusion strategies
- âœ… Model explainability & interpretability
- âœ… Production deployment
- âœ… Comprehensive documentation
- âœ… Performance evaluation
- âœ… Reproducibility

**Estimated Timeline**: 8-10 weeks | **Effort**: 80-120 hours

---

## ğŸ“ Support

- Check the [comprehensive README](README.md) in each phase folder
- Review configuration in [configs/config.yaml](configs/config.yaml)
- See utility functions in [utils/](utils/)

---

## ğŸ“ License

MIT License - Open source and free for academic use.

---

**Happy Building! ğŸ‰** Start with Phase 1 and progress through each phase systematically.